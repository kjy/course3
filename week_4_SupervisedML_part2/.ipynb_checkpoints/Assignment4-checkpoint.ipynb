{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "_You are currently looking at **version 1.0** of this notebook. To download notebooks and datafiles, as well as get help on Jupyter notebooks in the Coursera platform, visit the [Jupyter Notebook FAQ](https://www.coursera.org/learn/python-machine-learning/resources/bANLa) course resource._\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 4 - Understanding and Predicting Property Maintenance Fines\n",
    "\n",
    "This assignment is based on a data challenge from the Michigan Data Science Team ([MDST](http://midas.umich.edu/mdst/)). \n",
    "\n",
    "The Michigan Data Science Team ([MDST](http://midas.umich.edu/mdst/)) and the Michigan Student Symposium for Interdisciplinary Statistical Sciences ([MSSISS](https://sites.lsa.umich.edu/mssiss/)) have partnered with the City of Detroit to help solve one of the most pressing problems facing Detroit - blight. [Blight violations](http://www.detroitmi.gov/How-Do-I/Report/Blight-Complaint-FAQs) are issued by the city to individuals who allow their properties to remain in a deteriorated condition. Every year, the city of Detroit issues millions of dollars in fines to residents and every year, many of these fines remain unpaid. Enforcing unpaid blight fines is a costly and tedious process, so the city wants to know: how can we increase blight ticket compliance?\n",
    "\n",
    "The first step in answering this question is understanding when and why a resident might fail to comply with a blight ticket. This is where predictive modeling comes in. For this assignment, your task is to predict whether a given blight ticket will be paid on time.\n",
    "\n",
    "All data for this assignment has been provided to us through the [Detroit Open Data Portal](https://data.detroitmi.gov/). **Only the data already included in your Coursera directory can be used for training the model for this assignment.** Nonetheless, we encourage you to look into data from other Detroit datasets to help inform feature creation and model selection. We recommend taking a look at the following related datasets:\n",
    "\n",
    "* [Building Permits](https://data.detroitmi.gov/Property-Parcels/Building-Permits/xw2a-a7tf)\n",
    "* [Trades Permits](https://data.detroitmi.gov/Property-Parcels/Trades-Permits/635b-dsgv)\n",
    "* [Improve Detroit: Submitted Issues](https://data.detroitmi.gov/Government/Improve-Detroit-Submitted-Issues/fwz3-w3yn)\n",
    "* [DPD: Citizen Complaints](https://data.detroitmi.gov/Public-Safety/DPD-Citizen-Complaints-2016/kahe-efs3)\n",
    "* [Parcel Map](https://data.detroitmi.gov/Property-Parcels/Parcel-Map/fxkw-udwf)\n",
    "\n",
    "___\n",
    "\n",
    "We provide you with two data files for use in training and validating your models: train.csv and test.csv. Each row in these two files corresponds to a single blight ticket, and includes information about when, why, and to whom each ticket was issued. The target variable is compliance, which is True if the ticket was paid early, on time, or within one month of the hearing data, False if the ticket was paid after the hearing date or not at all, and Null if the violator was found not responsible. Compliance, as well as a handful of other variables that will not be available at test-time, are only included in train.csv.\n",
    "\n",
    "Note: All tickets where the violators were found not responsible are not considered during evaluation. They are included in the training set as an additional source of data for visualization, and to enable unsupervised and semi-supervised approaches. However, they are not included in the test set.\n",
    "\n",
    "<br>\n",
    "\n",
    "**File descriptions** (Use only this data for training your model!)\n",
    "\n",
    "    train.csv - the training set (all tickets issued 2004-2011)\n",
    "    test.csv - the test set (all tickets issued 2012-2016)\n",
    "    addresses.csv & latlons.csv - mapping from ticket id to addresses, and from addresses to lat/lon coordinates. \n",
    "     Note: misspelled addresses may be incorrectly geolocated.\n",
    "\n",
    "<br>\n",
    "\n",
    "**Data fields**\n",
    "\n",
    "train.csv & test.csv\n",
    "\n",
    "    ticket_id - unique identifier for tickets\n",
    "    agency_name - Agency that issued the ticket\n",
    "    inspector_name - Name of inspector that issued the ticket\n",
    "    violator_name - Name of the person/organization that the ticket was issued to\n",
    "    violation_street_number, violation_street_name, violation_zip_code - Address where the violation occurred\n",
    "    mailing_address_str_number, mailing_address_str_name, city, state, zip_code, non_us_str_code, country - Mailing address of the violator\n",
    "    ticket_issued_date - Date and time the ticket was issued\n",
    "    hearing_date - Date and time the violator's hearing was scheduled\n",
    "    violation_code, violation_description - Type of violation\n",
    "    disposition - Judgment and judgement type\n",
    "    fine_amount - Violation fine amount, excluding fees\n",
    "    admin_fee - $20 fee assigned to responsible judgments\n",
    "state_fee - $10 fee assigned to responsible judgments\n",
    "    late_fee - 10% fee assigned to responsible judgments\n",
    "    discount_amount - discount applied, if any\n",
    "    clean_up_cost - DPW clean-up or graffiti removal cost\n",
    "    judgment_amount - Sum of all fines and fees\n",
    "    grafitti_status - Flag for graffiti violations\n",
    "    \n",
    "train.csv only\n",
    "\n",
    "    payment_amount - Amount paid, if any\n",
    "    payment_date - Date payment was made, if it was received\n",
    "    payment_status - Current payment status as of Feb 1 2017\n",
    "    balance_due - Fines and fees still owed\n",
    "    collection_status - Flag for payments in collections\n",
    "    compliance [target variable for prediction] \n",
    "     Null = Not responsible\n",
    "     0 = Responsible, non-compliant\n",
    "     1 = Responsible, compliant\n",
    "    compliance_detail - More information on why each ticket was marked compliant or non-compliant\n",
    "\n",
    "\n",
    "___\n",
    "\n",
    "## Evaluation\n",
    "\n",
    "Your predictions will be given as the probability that the corresponding blight ticket will be paid on time.\n",
    "\n",
    "The evaluation metric for this assignment is the Area Under the ROC Curve (AUC). \n",
    "\n",
    "Your grade will be based on the AUC score computed for your classifier. A model which with an AUROC of 0.7 passes this assignment, over 0.75 will recieve full points.\n",
    "___\n",
    "\n",
    "For this assignment, create a function that trains a model to predict blight ticket compliance in Detroit using `train.csv`. Using this model, return a series of length 61001 with the data being the probability that each corresponding ticket from `test.csv` will be paid, and the index being the ticket_id.\n",
    "\n",
    "Example:\n",
    "\n",
    "    ticket_id\n",
    "       284932    0.531842\n",
    "       285362    0.401958\n",
    "       285361    0.105928\n",
    "       285338    0.018572\n",
    "                 ...\n",
    "       376499    0.208567\n",
    "       376500    0.818759\n",
    "       369851    0.018528\n",
    "       Name: compliance, dtype: float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def blight_model():\n",
    "    return answer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Memory Problems:\n",
    "\n",
    "The best way to avoid memory problems is to create two versions of the assignment notebook, one for development \n",
    "and one for submission. To avoid memory issues: \n",
    "\n",
    "1. Read only the columns you use in the final model, see read_csv has very useful parameter that can help reduce \n",
    "processing \n",
    "    usecols: provide a list of all columns to be read\n",
    "    \n",
    "    index_col: provide the name of the column to be used as index\n",
    "    \n",
    "    parse_dates: provide a list of columns that needs to be parsed)\n",
    "    \n",
    "    dtypes: provide a dictionary of column names as keys and types as values, use ‘str’ for string,’float’ for\n",
    "    float64, don’t use integer as NaN values are not allowed in integer data)\n",
    "    \n",
    "    converters: these can be useful for applying simple transformations to the columns, one example \n",
    "    {‘col_name’:lambda x: x.upper() if type(x)==str else x} can be used to convert all string items to upper case. \n",
    "    Only use with mostly non-numeric data\n",
    "    \n",
    "2. Replace or delete NaN values as early as possible in your code, use the same column datatype to fill each column, \n",
    "    e.g. if the column dtype is float64, use a float number, if the column dtype is DateTime or TimeStamp use \n",
    "    pd.to_datetime(‘Date here’) and if the dtype is Timedelta use pd.Timedelta(‘number units’) units can days, \n",
    "    months, etc..\n",
    "\n",
    "3. Remove redundant features, e.g. a column containing only one distinct value will add little information to your \n",
    "    learning model\n",
    "\n",
    "4. Keep your code neat, create functions to perform repetitive tasks, e.g. once you decided on the columns to use \n",
    "    and how to deal with NaN values and categorical data, create a function that you can use for both train and test\n",
    "\n",
    "5. Run your code on the online platform before submission, if it takes too long to run the code or restarts kernel, \n",
    "    this is an indication that the code needs modification/optimising. One example, you want to divide a pandas \n",
    "    series (ser) by a constant C, instead of division ser/C use multiplication ser*(1/C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "How to calculate AUC:\n",
    "\n",
    "train.csv is the only data available a the point when the model is designed, so to determine your learning model, \n",
    "and its parameters, you need to use train/test split or more preferably to avoid overfilling; cross_validation\n",
    "\n",
    "the test.csv is to be used only to predict the probability of class 1(i.e. blight ticket paid on time)\n",
    "\n",
    "If you achieve a high AUC on the training data but the grader returns a low AUC, you'll need to look at the model \n",
    "and whether it's being overfitted. the main cause of overfitting is the training data being very different from \n",
    "test data, that's why cross validation is important (I used Gridsearch setting scoring to 'roc_auc to choose my model')\n",
    "\n",
    "A second reason for overfitting is low number of training point, dropping all rows that contain a NaN value may result \n",
    "in much fewer data points that you would expect, that's why it's important to display your data at each step in the \n",
    "design stage.\n",
    "\n",
    "\n",
    "Things to try when grader's AUC is too low\n",
    "\n",
    "--different learning model, different parameters, use cross validation or multiple values of random_state when \n",
    "splitting train/test\n",
    "\n",
    "--add/remove features; you can achieve passing grader with even when using 2 features.\n",
    "\n",
    "--do you use scaling? is the method you're using suitable for this application? try a different scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticket_id</th>\n",
       "      <th>agency_name</th>\n",
       "      <th>inspector_name</th>\n",
       "      <th>violator_name</th>\n",
       "      <th>violation_street_number</th>\n",
       "      <th>violation_street_name</th>\n",
       "      <th>violation_zip_code</th>\n",
       "      <th>mailing_address_str_number</th>\n",
       "      <th>mailing_address_str_name</th>\n",
       "      <th>city</th>\n",
       "      <th>...</th>\n",
       "      <th>clean_up_cost</th>\n",
       "      <th>judgment_amount</th>\n",
       "      <th>payment_amount</th>\n",
       "      <th>balance_due</th>\n",
       "      <th>payment_date</th>\n",
       "      <th>payment_status</th>\n",
       "      <th>collection_status</th>\n",
       "      <th>grafitti_status</th>\n",
       "      <th>compliance_detail</th>\n",
       "      <th>compliance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22056</td>\n",
       "      <td>Buildings, Safety Engineering &amp; Env Department</td>\n",
       "      <td>Sims, Martinzie</td>\n",
       "      <td>INVESTMENT INC., MIDWEST MORTGAGE</td>\n",
       "      <td>2900.0</td>\n",
       "      <td>TYLER</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>S. WICKER</td>\n",
       "      <td>CHICAGO</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>305.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>305.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NO PAYMENT APPLIED</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>non-compliant by no payment</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27586</td>\n",
       "      <td>Buildings, Safety Engineering &amp; Env Department</td>\n",
       "      <td>Williams, Darrin</td>\n",
       "      <td>Michigan, Covenant House</td>\n",
       "      <td>4311.0</td>\n",
       "      <td>CENTRAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2959.0</td>\n",
       "      <td>Martin Luther King</td>\n",
       "      <td>Detroit</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>855.0</td>\n",
       "      <td>780.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>2005-06-02 00:00:00</td>\n",
       "      <td>PAID IN FULL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>compliant by late payment within 1 month</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22062</td>\n",
       "      <td>Buildings, Safety Engineering &amp; Env Department</td>\n",
       "      <td>Sims, Martinzie</td>\n",
       "      <td>SANDERS, DERRON</td>\n",
       "      <td>1449.0</td>\n",
       "      <td>LONGFELLOW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23658.0</td>\n",
       "      <td>P.O. BOX</td>\n",
       "      <td>DETROIT</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NO PAYMENT APPLIED</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>not responsible by disposition</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22084</td>\n",
       "      <td>Buildings, Safety Engineering &amp; Env Department</td>\n",
       "      <td>Sims, Martinzie</td>\n",
       "      <td>MOROSI, MIKE</td>\n",
       "      <td>1441.0</td>\n",
       "      <td>LONGFELLOW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>ST. CLAIR</td>\n",
       "      <td>DETROIT</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NO PAYMENT APPLIED</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>not responsible by disposition</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22093</td>\n",
       "      <td>Buildings, Safety Engineering &amp; Env Department</td>\n",
       "      <td>Sims, Martinzie</td>\n",
       "      <td>NATHANIEL, NEAL</td>\n",
       "      <td>2449.0</td>\n",
       "      <td>CHURCHILL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7449.0</td>\n",
       "      <td>CHURCHILL</td>\n",
       "      <td>DETROIT</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NO PAYMENT APPLIED</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>not responsible by disposition</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ticket_id                                     agency_name  \\\n",
       "0      22056  Buildings, Safety Engineering & Env Department   \n",
       "1      27586  Buildings, Safety Engineering & Env Department   \n",
       "2      22062  Buildings, Safety Engineering & Env Department   \n",
       "3      22084  Buildings, Safety Engineering & Env Department   \n",
       "4      22093  Buildings, Safety Engineering & Env Department   \n",
       "\n",
       "     inspector_name                      violator_name  \\\n",
       "0   Sims, Martinzie  INVESTMENT INC., MIDWEST MORTGAGE   \n",
       "1  Williams, Darrin           Michigan, Covenant House   \n",
       "2   Sims, Martinzie                    SANDERS, DERRON   \n",
       "3   Sims, Martinzie                       MOROSI, MIKE   \n",
       "4   Sims, Martinzie                    NATHANIEL, NEAL   \n",
       "\n",
       "   violation_street_number violation_street_name  violation_zip_code  \\\n",
       "0                   2900.0                 TYLER                 NaN   \n",
       "1                   4311.0               CENTRAL                 NaN   \n",
       "2                   1449.0            LONGFELLOW                 NaN   \n",
       "3                   1441.0            LONGFELLOW                 NaN   \n",
       "4                   2449.0             CHURCHILL                 NaN   \n",
       "\n",
       "   mailing_address_str_number mailing_address_str_name     city     ...      \\\n",
       "0                         3.0                S. WICKER  CHICAGO     ...       \n",
       "1                      2959.0       Martin Luther King  Detroit     ...       \n",
       "2                     23658.0                 P.O. BOX  DETROIT     ...       \n",
       "3                         5.0                ST. CLAIR  DETROIT     ...       \n",
       "4                      7449.0                CHURCHILL  DETROIT     ...       \n",
       "\n",
       "  clean_up_cost judgment_amount payment_amount balance_due  \\\n",
       "0           0.0           305.0            0.0       305.0   \n",
       "1           0.0           855.0          780.0        75.0   \n",
       "2           0.0             0.0            0.0         0.0   \n",
       "3           0.0             0.0            0.0         0.0   \n",
       "4           0.0             0.0            0.0         0.0   \n",
       "\n",
       "          payment_date      payment_status collection_status grafitti_status  \\\n",
       "0                  NaN  NO PAYMENT APPLIED               NaN             NaN   \n",
       "1  2005-06-02 00:00:00        PAID IN FULL               NaN             NaN   \n",
       "2                  NaN  NO PAYMENT APPLIED               NaN             NaN   \n",
       "3                  NaN  NO PAYMENT APPLIED               NaN             NaN   \n",
       "4                  NaN  NO PAYMENT APPLIED               NaN             NaN   \n",
       "\n",
       "                          compliance_detail  compliance  \n",
       "0               non-compliant by no payment         0.0  \n",
       "1  compliant by late payment within 1 month         1.0  \n",
       "2            not responsible by disposition         NaN  \n",
       "3            not responsible by disposition         NaN  \n",
       "4            not responsible by disposition         NaN  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df_train = pd.read_csv('/Users/karenyang/Desktop/DataScience_MachineLearning_Python/week_4_SupervisedML_part2/train.csv', \n",
    "                       encoding=\"latin1\", low_memory=False)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250306, 34)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape  # 250,306 examples with 34 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ticket_id                          0\n",
       "agency_name                        0\n",
       "inspector_name                     0\n",
       "violator_name                     34\n",
       "violation_street_number            0\n",
       "violation_street_name              0\n",
       "violation_zip_code            250306\n",
       "mailing_address_str_number      3602\n",
       "mailing_address_str_name           4\n",
       "city                               0\n",
       "state                             93\n",
       "zip_code                           1\n",
       "non_us_str_code               250303\n",
       "country                            0\n",
       "ticket_issued_date                 0\n",
       "hearing_date                   12491\n",
       "violation_code                     0\n",
       "violation_description              0\n",
       "disposition                        0\n",
       "fine_amount                        1\n",
       "admin_fee                          0\n",
       "state_fee                          0\n",
       "late_fee                           0\n",
       "discount_amount                    0\n",
       "clean_up_cost                      0\n",
       "judgment_amount                    0\n",
       "payment_amount                     0\n",
       "balance_due                        0\n",
       "payment_date                  209193\n",
       "payment_status                     0\n",
       "collection_status             213409\n",
       "grafitti_status               250305\n",
       "compliance_detail                  0\n",
       "compliance                     90426\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See how many nulls there are for each feature in the dataframe\n",
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Drop some features that are not of interest\n",
    "df_train.drop(['violation_zip_code','grafitti_status','inspector_name','violator_name', 'violation_street_number',\n",
    "         'violation_street_name','violation_zip_code','non_us_str_code', 'mailing_address_str_number',\n",
    "         'mailing_address_str_name', 'payment_date','payment_status','collection_status'],inplace=True,axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ticket_id                    0\n",
       "agency_name                  0\n",
       "city                         0\n",
       "state                       93\n",
       "zip_code                     1\n",
       "country                      0\n",
       "ticket_issued_date           0\n",
       "hearing_date             12491\n",
       "violation_code               0\n",
       "violation_description        0\n",
       "disposition                  0\n",
       "fine_amount                  1\n",
       "admin_fee                    0\n",
       "state_fee                    0\n",
       "late_fee                     0\n",
       "discount_amount              0\n",
       "clean_up_cost                0\n",
       "judgment_amount              0\n",
       "payment_amount               0\n",
       "balance_due                  0\n",
       "compliance_detail            0\n",
       "compliance               90426\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See how many nulls there are for each feature in the dataframe\n",
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# filter the dataframe to only include rows in which hearing_date is not null\n",
    "df_train = df_train[df_train.hearing_date.notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# if judgment_amount is 0.0 then set compliance equal to 1 for 90426 values to retain as many examples as possible\n",
    "df_train['compliance'][df_train.judgment_amount == 0.0] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ticket_id                 0\n",
       "agency_name               0\n",
       "city                      0\n",
       "state                    93\n",
       "zip_code                  0\n",
       "country                   0\n",
       "ticket_issued_date        0\n",
       "hearing_date              0\n",
       "violation_code            0\n",
       "violation_description     0\n",
       "disposition               0\n",
       "fine_amount               1\n",
       "admin_fee                 0\n",
       "state_fee                 0\n",
       "late_fee                  0\n",
       "discount_amount           0\n",
       "clean_up_cost             0\n",
       "judgment_amount           0\n",
       "payment_amount            0\n",
       "balance_due               0\n",
       "compliance_detail         0\n",
       "compliance                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One example has NaN so reset value to 0\n",
    "df_train[['fine_amount']] = df_train[['fine_amount']].fillna(value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ticket_id                 0\n",
       "agency_name               0\n",
       "city                      0\n",
       "state                    93\n",
       "zip_code                  0\n",
       "country                   0\n",
       "ticket_issued_date        0\n",
       "hearing_date              0\n",
       "violation_code            0\n",
       "violation_description     0\n",
       "disposition               0\n",
       "fine_amount               0\n",
       "admin_fee                 0\n",
       "state_fee                 0\n",
       "late_fee                  0\n",
       "discount_amount           0\n",
       "clean_up_cost             0\n",
       "judgment_amount           0\n",
       "payment_amount            0\n",
       "balance_due               0\n",
       "compliance_detail         0\n",
       "compliance                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    148222\n",
       "1.0     89593\n",
       "Name: compliance, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect the target variable, compliance\n",
    "#compliance [target variable for prediction] \n",
    "# Null = Not responsible\n",
    "# 0 = Responsible, non-compliant\n",
    "# 1 = Responsible, compliant\n",
    "# For this assignment, your task is to predict whether a given blight ticket will be paid on time.\n",
    "df_train.compliance.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "237815"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.compliance.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Buildings, Safety Engineering & Env Department    149037\n",
       "Department of Public Works                         71464\n",
       "Detroit Police Department                           8763\n",
       "Health Department                                   8549\n",
       "Neighborhood City Halls                                2\n",
       "Name: agency_name, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# agency names for blight ticket in the dataset\n",
    "#df_train.agency_name.unique()\n",
    "df_train.agency_name.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9-1-36(a)               93808\n",
       "9-1-81(a)               41052\n",
       "22-2-88                 27231\n",
       "9-1-104                 21725\n",
       "22-2-88(b)               6882\n",
       "22-2-45                  5223\n",
       "9-1-43(a) - (Dwellin     4959\n",
       "9-1-105                  4923\n",
       "9-1-110(a)               4684\n",
       "22-2-22                  3592\n",
       "9-1-103(C)               3442\n",
       "22-2-43                  2805\n",
       "19450901                 2769\n",
       "22-2-17                  1875\n",
       "22-2-61                  1395\n",
       "22-2-83(a)(b)(c)          807\n",
       "61-81.0100/32.0066        799\n",
       "9-1-82(d) - (Dwellin      791\n",
       "9-1-43(a) - (Structu      727\n",
       "22-2-83                   604\n",
       "61-5-21                   407\n",
       "9-1-206                   335\n",
       "22-2-88(a)                332\n",
       "9-1-43(a) - (Stories      324\n",
       "9-1-209                   321\n",
       "9-1-101                   287\n",
       "22-2-21(b)                276\n",
       "61-5-18                   262\n",
       "9-1-107                   218\n",
       "9-1-111                   200\n",
       "                        ...  \n",
       "9-1-381                     1\n",
       "9-1-354                     1\n",
       "9-1-444                     1\n",
       "61-111.0100/32.0066         1\n",
       "61-45.0000                  1\n",
       "9-1-434                     1\n",
       "61-86.0100/45.0807          1\n",
       "22-2-97                     1\n",
       "61-105.0100/32.066          1\n",
       "61-130.0000/130.0300        1\n",
       "61-116.0100/32.0031         1\n",
       "61-4-38                     1\n",
       "22-3-3                      1\n",
       "9-1-433                     1\n",
       "20160901                    1\n",
       "61-45.0000/45.0800          1\n",
       "9-1-332                     1\n",
       "9-1-352                     1\n",
       "61-122.0100/32.0066         1\n",
       "9-1-479                     1\n",
       "9-1-406                     1\n",
       "9-1-502                     1\n",
       "9-1-501                     1\n",
       "61-84.0100/32.0076B         1\n",
       "61-118.0100/32.0066         1\n",
       "9-1-308                     1\n",
       "9-1-471                     1\n",
       "9-1-443(b)                  1\n",
       "9-1-219                     1\n",
       "61-105.0100/32.0076B        1\n",
       "Name: violation_code, Length: 233, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# code violations in the particular dataset; too many to make categorical\n",
    "df_train.violation_code.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_train.judgment_amount.max()  \n",
    "df_train.judgment_amount.median()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Responsible by Default                138234\n",
       "Not responsible by Dismissal           47406\n",
       "Not responsible by City Dismissal      23820\n",
       "Responsible by Admission               13666\n",
       "Responsible by Determination            7563\n",
       "Not responsible by Determination        6542\n",
       "PENDING JUDGMENT                         387\n",
       "Responsible (Fine Waived) by Deter       190\n",
       "SET-ASIDE (PENDING JUDGMENT)               7\n",
       "Name: disposition, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.disposition.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ticket_id', 'agency_name', 'city', 'state', 'zip_code', 'country',\n",
       "       'ticket_issued_date', 'hearing_date', 'violation_code',\n",
       "       'violation_description', 'disposition', 'fine_amount', 'admin_fee',\n",
       "       'state_fee', 'late_fee', 'discount_amount', 'clean_up_cost',\n",
       "       'judgment_amount', 'payment_amount', 'balance_due', 'compliance_detail',\n",
       "       'compliance'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert to int to find the number of days from ticket_issued_date to the hearing_date\n",
    "df_train['time_to_hearing_date'] = (pd.to_datetime(df_train['hearing_date']).dt.date - \n",
    "                     pd.to_datetime(df_train['ticket_issued_date']).dt.date).fillna(pd.Timedelta('-1 days')).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    370\n",
       "1    378\n",
       "2    337\n",
       "4    337\n",
       "5    324\n",
       "Name: time_to_hearing_date, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['time_to_hearing_date'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.fine_amount.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.admin_fee.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.state_fee.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.late_fee.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "350.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.discount_amount.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.clean_up_cost.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "# Create categorical variable for agency_name\n",
    "le = preprocessing.LabelEncoder()\n",
    "an = df_train['agency_name'].tolist()\n",
    "le_model = le.fit_transform(an)\n",
    "# print(type(le_model))\n",
    "df_train['agency_name'] = le_model\n",
    "#df_train['agency_name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create categorical variable for disposition\n",
    "le2 = preprocessing.LabelEncoder()\n",
    "dis = df_train['disposition'].tolist()\n",
    "le_model2 = le2.fit_transform(dis)\n",
    "\n",
    "df_train['disposition'] = le_model2\n",
    "#df_train['disposition'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "237815"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up X_train, y_train for training dataset  # 237815 examples  \n",
    "X_train = df_train[['time_to_hearing_date','fine_amount', 'admin_fee','state_fee', 'late_fee','discount_amount', 'judgment_amount']]\n",
    "y_train = df_train['compliance']\n",
    "y_train.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in test dataset; no y_values in dataset, grader has y_test data\n",
    "# /Users/karenyang/Desktop/DataScience_MachineLearning_Python/week_4_SupervisedML_part2/\n",
    "\n",
    "df_test = pd.read_csv('/Users/karenyang/Desktop/DataScience_MachineLearning_Python/week_4_SupervisedML_part2/test.csv', \n",
    "          encoding=\"latin1\",  \n",
    "          low_memory=False,\n",
    "          index_col=['ticket_id'],    \n",
    "          usecols=['agency_name', 'ticket_id', 'ticket_issued_date', 'hearing_date', 'fine_amount', 'admin_fee', \n",
    "                    'state_fee', 'late_fee', 'discount_amount','disposition', 'judgment_amount'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61001, 10)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "agency_name              0\n",
       "ticket_issued_date       0\n",
       "hearing_date          2197\n",
       "disposition              0\n",
       "fine_amount              0\n",
       "admin_fee                0\n",
       "state_fee                0\n",
       "late_fee                 0\n",
       "discount_amount          0\n",
       "judgment_amount          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See how many nulls there are for each feature in the dataframe\n",
    "df_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fill NaNs with 0 values to keep dataset at 61001 examples for grader\n",
    "df_test['hearing_date'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "# Create categorical variable for agency_name\n",
    "\n",
    "le3 = preprocessing.LabelEncoder()\n",
    "an3 = df_test['agency_name'].tolist()\n",
    "le_model3 = le3.fit_transform(an3)\n",
    "\n",
    "#print(type(le_model))\n",
    "\n",
    "df_test['agency_name'] = le_model3\n",
    "#df_test['agency_name'].unique()\n",
    "\n",
    "\n",
    "# Create categorical variable for disposition\n",
    "le4 = preprocessing.LabelEncoder()\n",
    "dis4 = df_test['disposition'].tolist()\n",
    "le_model4 = le4.fit_transform(dis4)\n",
    "\n",
    "df_test['disposition'] = le_model4\n",
    "#df_test['disposition'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ticket_id\n",
       "284932    2012-01-04 14:00:00\n",
       "285362    2012-01-05 09:50:00\n",
       "285361    2012-01-05 09:50:00\n",
       "285338    2012-01-05 10:25:00\n",
       "285346    2012-01-05 10:20:00\n",
       "Name: ticket_issued_date, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['ticket_issued_date'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert to int to find the number of days from ticket_issued_date to the hearing_date\n",
    "df_test['time_to_hearing_date'] = (pd.to_datetime(df_test['hearing_date']).dt.date - \n",
    "                     pd.to_datetime(df_test['ticket_issued_date']).dt.date).fillna(pd.Timedelta('-1 days')).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ticket_id\n",
       "284932    15\n",
       "285362    32\n",
       "285361    32\n",
       "285338    33\n",
       "285346    40\n",
       "Name: time_to_hearing_date, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['time_to_hearing_date'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set up X_test for test dataset\n",
    "X_test = df_test[['time_to_hearing_date','fine_amount', 'admin_fee','state_fee', 'late_fee','discount_amount', 'judgment_amount']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# instantiate the logistic model\n",
    "clf = LogisticRegression()\n",
    "\n",
    "logreg_model = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate the predicted values\n",
    "y_pred = logreg_model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94174687920170186"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate roc_auc score for training model\n",
    "x = roc_auc_score(y_train,y_pred)  \n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/karenyang/anaconda/lib/python3.6/site-packages/sklearn/linear_model/base.py:352: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    }
   ],
   "source": [
    "# Obtain the predicted probabilities for the X_test dataset\n",
    "y_pred_proba = logreg_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# convert to list\n",
    "list_predicted_probabilities = list(y_pred_proba)\n",
    "\n",
    "# convert to panda series\n",
    "series_predicted_probabilities = pd.Series(list_predicted_probabilities).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>compliance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ticket_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>284932</th>\n",
       "      <td>0.062065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285362</th>\n",
       "      <td>0.007397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285361</th>\n",
       "      <td>0.078228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285338</th>\n",
       "      <td>0.060755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285346</th>\n",
       "      <td>0.077503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           compliance\n",
       "ticket_id            \n",
       "284932       0.062065\n",
       "285362       0.007397\n",
       "285361       0.078228\n",
       "285338       0.060755\n",
       "285346       0.077503"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add values of series to dataframe\n",
    "df_test['compliance'] = series_predicted_probabilities.values\n",
    "\n",
    "df_final = df_test[['compliance']]\n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ticket_id\n",
       "286183    0.061334\n",
       "288330    0.106148\n",
       "286909    0.087834\n",
       "286908    0.007333\n",
       "286102    0.061919\n",
       "287151    0.059825\n",
       "288422    0.082332\n",
       "286426    0.028085\n",
       "286430    0.028085\n",
       "286424    0.187098\n",
       "Name: compliance, dtype: float32"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer = df_final['compliance'] \n",
    "answer[500:510]  # sample of predicted probabilities for test data\n",
    "#return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Grader output:\n",
    "\n",
    "Your AUC of  0.759420902783 was awarded a value of 1.0 out of  1.0 total grades"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The point of a ROC curve (and the area under it) is that you study the precision-recall tradeoff as the \n",
    "classification threshold is varied. By default in a binary classification task, if your classifier's score is  > 0.5, \n",
    "then class1 is predicted, otherwise class0 is predicted. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "python-machine-learning",
   "graded_item_id": "nNS8l",
   "launcher_item_id": "yWWk7",
   "part_id": "w8BSS"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
